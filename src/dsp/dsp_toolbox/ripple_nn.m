function [Y,Xf,Af] = myNeuralNetworkFunction(X,~,~)

% thresh X=0.282

%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 27-Mar-2018 10:50:20.
%
% [Y] = myNeuralNetworkFunction(X,~,~) takes these arguments:
%
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = Qx6 matrix, input #1 at timestep ts.
%
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = Qx1 matrix, output #1 at timestep ts.
%
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [26;0.930930277889763;0.931563347893145;-5446778011.81847;0.412774998364008;0.040964933396031];
x1_step1.gain = [9.29635861632998e-06;0.0190100194297021;0.0190076277367875;3.67189580199198e-10;0.0408007589936041;0.141329346303657];
x1_step1.ymin = -1;

% Layer 1
b1 = [-1.5944932973053698166;-1.5773786346207139264;-1.0844678956265396685;1.0365539462319675046;0.026885893926027661788;-0.72942827676122312663;0.80312081850260008675;-1.2166753896335698037;1.738156330092839319;-2.3653312012511049645];
IW1_1 = [1.8554062144535146128 -0.4647988248100720643 -1.038434252120978174 -0.042903035186450416694 -3.8771020687979400599 1.6109472037049827886;1.0018950011315870263 1.0521477607612621519 1.274269907051052142 0.70147586539798145733 0.45650052040895028327 -0.053383878907806221747;1.1268264023837135657 -0.092685178453524710851 -0.14149584459706024409 0.8289475356540257911 0.10719065748717872266 1.4894381776602827472;-0.53953827575199997391 -0.28851291327527150976 1.3986233512789534306 -0.081833426679353921118 -0.9655952830795716535 1.2590414508864016252;0.62346567089778448523 0.45374410112854485222 0.39269606551362534752 1.1795536239899362396 -1.46409873907635113 -0.36519491115831370642;-1.3005929854058615458 -0.31387495854384511729 -0.50444846833451029156 -0.87208162172642589294 -3.7182791068245641952 4.5259046854810431881;0.5755707781103802656 1.4584670824649130783 -0.96385268534366408399 0.42338868293721476643 -0.50857691272307847807 1.8435378685991654635;-1.1423127374061772255 1.2606764733000968004 0.023559882489735915756 -0.45265479863069219002 -1.4652694533686809741 -0.270012132885221523;1.3019697536678698224 -0.55362286026600204814 -0.69142363766155379157 1.0690235747159866353 -0.50252132308670305338 0.49029083749603191711;-0.93100257175071132743 -0.881080758239911499 0.68473969991208594177 0.08430918103969078925 -0.72873366563284736053 -0.75751048435126988601];

% Layer 2
b2 = -0.85810853068004055988;
LW2_1 = [-3.2966188400179476936 2.3508560304133316876 0.35795958214600187564 -1.5342989945263525442 -0.45086402689456489545 -4.5835158029275815394 -1.8667475628166088075 -0.60500315140209515175 -1.4076866800710972072 0.86518567735145235353];

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX
    X = {X};
end

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
    Q = size(X{1},1); % samples/series
else
    Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS
    
    % Input 1
    X{1,ts} = X{1,ts}';
    Xp1 = mapminmax_apply(X{1,ts},x1_step1);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = logsig_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Output 1
    Y{1,ts} = a2;
    Y{1,ts} = Y{1,ts}';
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX
    Y = cell2mat(Y);
end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
y = bsxfun(@minus,x,settings.xoffset);
y = bsxfun(@times,y,settings.gain);
y = bsxfun(@plus,y,settings.ymin);
end

% Sigmoid Positive Transfer Function
function a = logsig_apply(n,~)
a = 1 ./ (1 + exp(-n));
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
